{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test_folder=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from performance_measure import calculate_metrics\n",
    "from models import lenet,resnet,efficient_net\n",
    "import config\n",
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "import torch.utils.data as data\n",
    "from torchvision.datasets import ImageFolder\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(path,data_transform):\n",
    "    dataset=ImageFolder(path,transform=data_transform)\n",
    "    dataloader=data.DataLoader(dataset,batch_size=config.batch_size)\n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=['lenet','resnet','resnet256']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the models and calculating the metrics\n",
    "models=['lenet','resnet','resnet256']\n",
    "print('Total files in the test folder:',len(os.listdir(path_test_folder)))\n",
    "for model in models:\n",
    "        model_name=model\n",
    "        print('Starting Evaluation with Model - ',model_name)\n",
    "        out_dir=os.path.join(f'saved_models',f'{model_name}_saved_model')\n",
    "        data_transforms=torch.load(os.path.join(out_dir,f'transforms_{model_name}.pt'))\n",
    "        test_loader=get_dataloader(path_test_folder,data_transforms)\n",
    "        if(model=='lenet'):\n",
    "            seq_model = lenet.LeNet(config.num_classes)\n",
    "        elif(model=='resnet' or model=='resnet256'):\n",
    "            seq_model = resnet.CustomResNet(config.num_classes).get_model()\n",
    "        elif(model=='efficient_net'):\n",
    "            enet_model = efficient_net.CustomEfficientNet(config.num_classes).get_model()\n",
    "        seq_model.load_state_dict(torch.load(os.path.join(out_dir,f'state_{model_name}.pt'),map_location=torch.device('cpu')))\n",
    "        #calcualte the metrics 5 times and take the average\n",
    "        out=calculate_metrics(test_loader,seq_model,3,True)\n",
    "        #take average of the metrics\n",
    "        print('-'*50)\n",
    "        print('Final Score for ',model_name)\n",
    "        print('Accuracy: {:.2f}%'.format(out['accuracy']))\n",
    "        print('Precision: {:.2f}'.format(out['precision']))\n",
    "        print('Recall: {:.2f}'.format(out['recall']))\n",
    "        print('F1 Score: {:.2f}'.format(out['f1_score']))\n",
    "        print('Loss: {:.4f}'.format(out['loss']))\n",
    "        print('-'*50)\n",
    "        print('*'*50)\n",
    "        print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
